{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andrerizzo/complete_project/blob/code/Modelagem_with_Bayesian_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yzw72g-ICLeg"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import sklearn.linear_model as sk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXE36bzGCLew",
    "outputId": "c0df950a-f8d1-4517-d8b1-ba6285305d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_width  petal_length_trans\n",
      "0            3.0           -1.222611\n",
      "1            3.2           -1.641609\n",
      "2            3.1           -0.860957\n",
      "3            3.6           -1.222611\n",
      "4            3.9           -0.518618\n",
      "..           ...                 ...\n",
      "144          3.0            0.767216\n",
      "145          2.5            0.537961\n",
      "146          3.0            0.767216\n",
      "147          3.4            0.860957\n",
      "148          3.0            0.658733\n",
      "\n",
      "[149 rows x 2 columns]\n",
      "              class\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "144  Iris-virginica\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "\n",
      "[149 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "url1 = 'https://raw.githubusercontent.com/andrerizzo/complete_project/dataset/iris_predictors.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/andrerizzo/complete_project/dataset/iris_response.csv'\n",
    "X = pd.read_csv(url1)\n",
    "y = pd.read_csv(url2)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S2bLFDMCLe0",
    "outputId": "e76e0e5b-475e-441e-9f2c-131a860cb344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_width  petal_length_trans\n",
      "27           3.4           -1.222611\n",
      "97           2.5           -0.433806\n",
      "96           2.9           -0.025237\n",
      "69           3.2            0.369964\n",
      "18           3.8           -0.860957\n",
      "..           ...                 ...\n",
      "9            3.7           -0.860957\n",
      "103          3.0            1.297001\n",
      "67           2.2            0.126509\n",
      "117          2.6            2.710835\n",
      "47           3.7           -0.860957\n",
      "\n",
      "[119 rows x 2 columns]\n",
      "     sepal_width  petal_length_trans\n",
      "133          2.6            1.046561\n",
      "109          3.2            0.658733\n",
      "59           2.0           -0.369964\n",
      "80           2.4           -0.325284\n",
      "7            2.9           -1.222611\n",
      "104          3.0            1.986482\n",
      "140          3.1            0.658733\n",
      "95           2.9           -0.075776\n",
      "118          2.2            0.537961\n",
      "84           3.4            0.126509\n",
      "33           3.1           -0.860957\n",
      "44           3.0           -1.222611\n",
      "54           2.8            0.126509\n",
      "24           3.0           -0.627699\n",
      "37           3.0           -1.641609\n",
      "132          2.8            0.658733\n",
      "111          3.0            0.923581\n",
      "73           2.9           -0.025237\n",
      "16           3.5           -1.222611\n",
      "45           3.8           -0.627699\n",
      "40           2.3           -1.641609\n",
      "8            3.1           -0.860957\n",
      "85           3.1            0.290005\n",
      "22           3.3           -0.518618\n",
      "62           2.9            0.290005\n",
      "94           3.0           -0.075776\n",
      "90           3.0            0.220472\n",
      "26           3.5           -0.860957\n",
      "43           3.8           -0.461702\n",
      "134          3.0            1.641609\n",
      "               class\n",
      "27       Iris-setosa\n",
      "97   Iris-versicolor\n",
      "96   Iris-versicolor\n",
      "69   Iris-versicolor\n",
      "18       Iris-setosa\n",
      "..               ...\n",
      "9        Iris-setosa\n",
      "103   Iris-virginica\n",
      "67   Iris-versicolor\n",
      "117   Iris-virginica\n",
      "47       Iris-setosa\n",
      "\n",
      "[119 rows x 1 columns]\n",
      "               class\n",
      "133   Iris-virginica\n",
      "109   Iris-virginica\n",
      "59   Iris-versicolor\n",
      "80   Iris-versicolor\n",
      "7        Iris-setosa\n",
      "104   Iris-virginica\n",
      "140   Iris-virginica\n",
      "95   Iris-versicolor\n",
      "118   Iris-virginica\n",
      "84   Iris-versicolor\n",
      "33       Iris-setosa\n",
      "44       Iris-setosa\n",
      "54   Iris-versicolor\n",
      "24       Iris-setosa\n",
      "37       Iris-setosa\n",
      "132   Iris-virginica\n",
      "111   Iris-virginica\n",
      "73   Iris-versicolor\n",
      "16       Iris-setosa\n",
      "45       Iris-setosa\n",
      "40       Iris-setosa\n",
      "8        Iris-setosa\n",
      "85   Iris-versicolor\n",
      "22       Iris-setosa\n",
      "62   Iris-versicolor\n",
      "94   Iris-versicolor\n",
      "90   Iris-versicolor\n",
      "26       Iris-setosa\n",
      "43       Iris-setosa\n",
      "134   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "11hUK_6LCLe1"
   },
   "outputs": [],
   "source": [
    "# Create list to store accuracy results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZnE6YwdCLe3",
    "outputId": "becdd51e-9587-4399-b3ab-4ea94e5d8d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933 (0.057)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Define model\n",
    "classifier = LDA()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['LDA'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1qHIqZjCLe4",
    "outputId": "4164350a-7c82-4f5c-afba-8872099be9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935 (0.064)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['kNN'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DMFLfnxCLe6",
    "outputId": "c702fb3b-6fe2-4cc0-909b-3401e0b02f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953 (0.055)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define model\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['SVM'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTaJSCNaCLe7",
    "outputId": "bd237879-7b39-4959-cd8d-7a3b4473f90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.881 (0.076)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['SGD'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZpjsn29CLe9",
    "outputId": "61c7ed26-cb05-4815-f190-abe117f7697e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924 (0.054)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define model\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Gaussian Naive Bayes'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sWd26iaCLe9",
    "outputId": "f1b9b275-faab-44b1-e814-183f22ddc154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917 (0.071)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Decision Trees'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOdavQriCLe_",
    "outputId": "7e731c7d-846b-41a1-ba43-31cc5f448988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942 (0.059)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Random Forest'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_Vxj478CLfB",
    "outputId": "a8124e66-4e51-4f43-cd10-0a939b879735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754 (0.111)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = AdaBoostClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['AdaBoost'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4ltPXRcCLfC",
    "outputId": "6e109a03-f86e-4c9e-8dbe-d49e4071c7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.948 (0.057)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = MLPClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['MLP Classifier'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cDMF8j5CLfD",
    "outputId": "a0508d60-71ea-4c34-9b16-22f533eb0342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SVM', 0.9530158730158731), ('MLP Classifier', 0.9484126984126984), ('Random Forest', 0.9417460317460318), ('kNN', 0.9349206349206349), ('LDA', 0.9326984126984127), ('Gaussian Naive Bayes', 0.9236507936507937), ('Decision Trees', 0.916984126984127), ('SGD', 0.8809523809523812), ('AdaBoost', 0.7542857142857144)]\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print(sorted(results.items(), reverse=True, key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIAP90nsCLfE"
   },
   "source": [
    "I will select the first five algorithms to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZlHBfSBUT4La"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "Log sync requires rsync to be installed.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4.333381003524921, 'kernel': 'poly', 'degree': 1, 'gamma': 0.23132593197812873, 'coef0': 0.055529549019350644, 'shrinking': True, 'tol': 0.0019692598741096906, 'decision_function_shape': 'ovo'}\n"
     ]
    }
   ],
   "source": [
    "# # Hyperparameter tuning - SVM (using tune_sklearn)\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['C'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "hparams['degree'] = (1,5, \"uniform\")\n",
    "hparams['gamma'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['coef0'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['shrinking'] = [True, False]\n",
    "hparams['tol'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(SVC(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian', \n",
    "                           random_state = 1                                                        \n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre.rizzo\\Anaconda3\\lib\\site-packages\\skopt\\space\\space.py:502: RuntimeWarning: divide by zero encountered in log10\n",
      "  np.log10(self.low) / self.log_base,\n",
      "C:\\Users\\andre.rizzo\\Anaconda3\\lib\\site-packages\\skopt\\space\\space.py:504: RuntimeWarning: divide by zero encountered in log10\n",
      "  np.log10(self.low) / self.log_base)\n",
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 11.171401977539062 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 3.1981592178344727 seconds to complete, which may be a performance bottleneck.\n",
      "The `start_trial` operation took 10.6755850315094 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n",
      "The `process_trial` operation took 0.6143577098846436 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 122, 'criterion': 'gini', 'max_depth': 90, 'min_samples_split': 6.827718408898428e-10, 'min_samples_leaf': 0.03589034539383807, 'min_weight_fraction_leaf': 0, 'max_features': 'log2', 'max_leaf_nodes': 60, 'min_impurity_decrease': 229.36756118316796, 'oob_score': False, 'class_weight': 'balanced', 'ccp_alpha': 21.27667792818874}\n"
     ]
    }
   ],
   "source": [
    "# # Hyperparameter tuning - Random Forest (using tune_sklearn)\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['n_estimators'] = (1, 1000, 'uniform')\n",
    "hparams['criterion'] = ['gini', 'entropy']\n",
    "hparams['max_depth'] = (1,100, \"uniform\")\n",
    "hparams['min_samples_split'] = (1e-10, 9e-10, \"log-uniform\")\n",
    "hparams['min_samples_leaf'] = (1e-6, 0.5, \"log-uniform\")\n",
    "hparams['min_weight_fraction_leaf'] = (0, 0.5, \"log-uniform\")\n",
    "hparams['max_features'] = ['auto', 'sqrt', 'log2']\n",
    "hparams['max_leaf_nodes'] = (1,100, \"uniform\")\n",
    "hparams['min_impurity_decrease'] = (1e-6, 1e10, \"log-uniform\")\n",
    "#hparams['bootstrap'] = (True, False)\n",
    "hparams['oob_score'] = (True, False)\n",
    "#hparams['n_jobs'] = (-1, 1)\n",
    "hparams['class_weight'] = ('balanced', 'balanced_subsample')\n",
    "hparams['ccp_alpha'] = (1e-6, 1e10, \"log-uniform\")\n",
    "\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(RFC(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian',\n",
    "                           refit = True,\n",
    "                           verbose=0\n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr', 'shrinkage': None, 'tol': 423125.33666109777}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - Random Forest (using tune_sklearn)\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['solver'] = ['lsqr', 'eigen']\n",
    "hparams['shrinkage'] = (None,'auto')\n",
    "#hparams['n_components'] = (1, 2)\n",
    "hparams['tol'] = (1e-6, 1e10, \"log-uniform\")\n",
    "\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(LDA(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian',\n",
    "                           refit = True,\n",
    "                           verbose=0\n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 10,  0],\n",
       "       [ 0,  0,  8]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM model using computed hyperparameters\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import sklearn.metrics as clf_metrics\n",
    "\n",
    "\n",
    "'''\n",
    "'C': 0.4632668689058262, \n",
    "'kernel': 'poly'\n",
    "'degree': 3\n",
    "'gamma': 0.008637473528650222, \n",
    "'coef0': 14.819346866218453\n",
    "'shrinking': True\n",
    "'tol': 0.01526285467501595\n",
    "'decision_function_shape': 'ovo'}\n",
    "'''\n",
    "\n",
    "model = SVC(C=0.4632668689058262, \n",
    "            kernel='poly',\n",
    "            degree=3,\n",
    "            gamma=0.008637473528650222,\n",
    "            coef0=14.819346866218453,\n",
    "            shrinking=True, \n",
    "            tol=0.01526285467501595, \n",
    "            decision_function_shape='ovo'\n",
    "           )\n",
    "\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "clf_metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Modelagem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
