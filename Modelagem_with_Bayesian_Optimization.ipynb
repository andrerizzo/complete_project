{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andrerizzo/complete_project/blob/code/Modelagem_with_Bayesian_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yzw72g-ICLeg"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import sklearn.linear_model as sk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXE36bzGCLew",
    "outputId": "c0df950a-f8d1-4517-d8b1-ba6285305d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_width  petal_length_trans\n",
      "0            3.0           -1.222611\n",
      "1            3.2           -1.641609\n",
      "2            3.1           -0.860957\n",
      "3            3.6           -1.222611\n",
      "4            3.9           -0.518618\n",
      "..           ...                 ...\n",
      "144          3.0            0.767216\n",
      "145          2.5            0.537961\n",
      "146          3.0            0.767216\n",
      "147          3.4            0.860957\n",
      "148          3.0            0.658733\n",
      "\n",
      "[149 rows x 2 columns]\n",
      "              class\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "144  Iris-virginica\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "\n",
      "[149 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "url1 = 'https://raw.githubusercontent.com/andrerizzo/complete_project/dataset/iris_predictors.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/andrerizzo/complete_project/dataset/iris_response.csv'\n",
    "X = pd.read_csv(url1)\n",
    "y = pd.read_csv(url2)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S2bLFDMCLe0",
    "outputId": "e76e0e5b-475e-441e-9f2c-131a860cb344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_width  petal_length_trans\n",
      "27           3.4           -1.222611\n",
      "97           2.5           -0.433806\n",
      "96           2.9           -0.025237\n",
      "69           3.2            0.369964\n",
      "18           3.8           -0.860957\n",
      "..           ...                 ...\n",
      "9            3.7           -0.860957\n",
      "103          3.0            1.297001\n",
      "67           2.2            0.126509\n",
      "117          2.6            2.710835\n",
      "47           3.7           -0.860957\n",
      "\n",
      "[119 rows x 2 columns]\n",
      "     sepal_width  petal_length_trans\n",
      "133          2.6            1.046561\n",
      "109          3.2            0.658733\n",
      "59           2.0           -0.369964\n",
      "80           2.4           -0.325284\n",
      "7            2.9           -1.222611\n",
      "104          3.0            1.986482\n",
      "140          3.1            0.658733\n",
      "95           2.9           -0.075776\n",
      "118          2.2            0.537961\n",
      "84           3.4            0.126509\n",
      "33           3.1           -0.860957\n",
      "44           3.0           -1.222611\n",
      "54           2.8            0.126509\n",
      "24           3.0           -0.627699\n",
      "37           3.0           -1.641609\n",
      "132          2.8            0.658733\n",
      "111          3.0            0.923581\n",
      "73           2.9           -0.025237\n",
      "16           3.5           -1.222611\n",
      "45           3.8           -0.627699\n",
      "40           2.3           -1.641609\n",
      "8            3.1           -0.860957\n",
      "85           3.1            0.290005\n",
      "22           3.3           -0.518618\n",
      "62           2.9            0.290005\n",
      "94           3.0           -0.075776\n",
      "90           3.0            0.220472\n",
      "26           3.5           -0.860957\n",
      "43           3.8           -0.461702\n",
      "134          3.0            1.641609\n",
      "               class\n",
      "27       Iris-setosa\n",
      "97   Iris-versicolor\n",
      "96   Iris-versicolor\n",
      "69   Iris-versicolor\n",
      "18       Iris-setosa\n",
      "..               ...\n",
      "9        Iris-setosa\n",
      "103   Iris-virginica\n",
      "67   Iris-versicolor\n",
      "117   Iris-virginica\n",
      "47       Iris-setosa\n",
      "\n",
      "[119 rows x 1 columns]\n",
      "               class\n",
      "133   Iris-virginica\n",
      "109   Iris-virginica\n",
      "59   Iris-versicolor\n",
      "80   Iris-versicolor\n",
      "7        Iris-setosa\n",
      "104   Iris-virginica\n",
      "140   Iris-virginica\n",
      "95   Iris-versicolor\n",
      "118   Iris-virginica\n",
      "84   Iris-versicolor\n",
      "33       Iris-setosa\n",
      "44       Iris-setosa\n",
      "54   Iris-versicolor\n",
      "24       Iris-setosa\n",
      "37       Iris-setosa\n",
      "132   Iris-virginica\n",
      "111   Iris-virginica\n",
      "73   Iris-versicolor\n",
      "16       Iris-setosa\n",
      "45       Iris-setosa\n",
      "40       Iris-setosa\n",
      "8        Iris-setosa\n",
      "85   Iris-versicolor\n",
      "22       Iris-setosa\n",
      "62   Iris-versicolor\n",
      "94   Iris-versicolor\n",
      "90   Iris-versicolor\n",
      "26       Iris-setosa\n",
      "43       Iris-setosa\n",
      "134   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "11hUK_6LCLe1"
   },
   "outputs": [],
   "source": [
    "# Create list to store accuracy results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZnE6YwdCLe3",
    "outputId": "becdd51e-9587-4399-b3ab-4ea94e5d8d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.933 (0.057)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - LDA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Define model\n",
    "classifier = LDA()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['LDA'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1qHIqZjCLe4",
    "outputId": "4164350a-7c82-4f5c-afba-8872099be9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935 (0.064)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['kNN'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9DMFLfnxCLe6",
    "outputId": "c702fb3b-6fe2-4cc0-909b-3401e0b02f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.953 (0.055)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define model\n",
    "classifier = SVC(kernel='linear')\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['SVM'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTaJSCNaCLe7",
    "outputId": "bd237879-7b39-4959-cd8d-7a3b4473f90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903 (0.074)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - SGD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = SGDClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['SGD'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZpjsn29CLe9",
    "outputId": "61c7ed26-cb05-4815-f190-abe117f7697e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924 (0.054)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define model\n",
    "classifier = GaussianNB()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Gaussian Naive Bayes'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sWd26iaCLe9",
    "outputId": "f1b9b275-faab-44b1-e814-183f22ddc154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.917 (0.071)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Decision Trees'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOdavQriCLe_",
    "outputId": "7e731c7d-846b-41a1-ba43-31cc5f448988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.937 (0.060)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['Random Forest'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x_Vxj478CLfB",
    "outputId": "a8124e66-4e51-4f43-cd10-0a939b879735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754 (0.111)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = AdaBoostClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['AdaBoost'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4ltPXRcCLfC",
    "outputId": "6e109a03-f86e-4c9e-8dbe-d49e4071c7aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.946 (0.062)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Models - MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define model\n",
    "classifier = MLPClassifier()\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(classifier, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (np.mean(scores),np.std(scores)))\n",
    "\n",
    "results['MLP Classifier'] = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cDMF8j5CLfD",
    "outputId": "a0508d60-71ea-4c34-9b16-22f533eb0342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SVM', 0.9530158730158731), ('MLP Classifier', 0.946031746031746), ('Random Forest', 0.9373015873015873), ('kNN', 0.9349206349206349), ('LDA', 0.9326984126984127), ('Gaussian Naive Bayes', 0.9236507936507937), ('Decision Trees', 0.916984126984127), ('SGD', 0.9031746031746033), ('AdaBoost', 0.7542857142857144)]\n"
     ]
    }
   ],
   "source": [
    "# Show results\n",
    "print(sorted(results.items(), reverse=True, key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIAP90nsCLfE"
   },
   "source": [
    "I will select the first five algorithms to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Sn4VV24XCLfF"
   },
   "source": [
    "# Hyperparameter tuning - SVM\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['C'] = (1e-6, 100.0)\n",
    "hparams['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "hparams['degree'] = (1,5)\n",
    "hparams['gamma'] = (1e-6, 100.0)\n",
    "hparams['coef0'] = (1e-6, 100.0)\n",
    "hparams['shrinking'] = [True, False]\n",
    "hparams['tol'] = (1e-6, 100.0)\n",
    "hparams['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "# Define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "search = BayesSearchCV(estimator=svm.SVC(), search_spaces=hparams, n_jobs=-1, cv=cv)\n",
    "\n",
    "# Perform the search\n",
    "search.fit(X, y)\n",
    "\n",
    "# Report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZlHBfSBUT4La"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `process_trial` operation took 0.6793889999389648 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.4632668689058262, 'kernel': 'poly', 'degree': 3, 'gamma': 0.008637473528650222, 'coef0': 14.819346866218453, 'shrinking': True, 'tol': 0.01526285467501595, 'decision_function_shape': 'ovo'}\n"
     ]
    }
   ],
   "source": [
    "# # Hyperparameter tuning - SVM (using tune_sklearn)\n",
    "#pip install ray[tune] tune-sklearn\n",
    "#pip install scikit-optimize\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#from skopt import BayesSearchCV\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['C'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "hparams['degree'] = (1,5, \"uniform\")\n",
    "hparams['gamma'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['coef0'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['shrinking'] = [True, False]\n",
    "hparams['tol'] = (1e-6, 100.0, \"log-uniform\")\n",
    "hparams['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(SVC(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian',\n",
    "                           refit = True,\n",
    "                           verbose=0\n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre.rizzo\\Anaconda3\\lib\\site-packages\\skopt\\space\\space.py:502: RuntimeWarning: divide by zero encountered in log10\n",
      "  np.log10(self.low) / self.log_base,\n",
      "C:\\Users\\andre.rizzo\\Anaconda3\\lib\\site-packages\\skopt\\space\\space.py:504: RuntimeWarning: divide by zero encountered in log10\n",
      "  np.log10(self.low) / self.log_base)\n",
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "The `start_trial` operation took 8.495230674743652 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 9.933154344558716 seconds to complete, which may be a performance bottleneck.\n",
      "The `start_trial` operation took 11.854437828063965 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 9.020771741867065 seconds to complete, which may be a performance bottleneck.\n",
      "The `start_trial` operation took 10.98993706703186 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 6.181536674499512 seconds to complete, which may be a performance bottleneck.\n",
      "The `start_trial` operation took 4.8135786056518555 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n",
      "The `start_trial` operation took 8.041280746459961 seconds to complete, which may be a performance bottleneck.\n",
      "The `start_trial` operation took 14.988099575042725 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "The `start_trial` operation took 7.743265390396118 seconds to complete, which may be a performance bottleneck.\n",
      "The `process_trial` operation took 0.6662507057189941 seconds to complete, which may be a performance bottleneck.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 905, 'criterion': 'gini', 'max_depth': 68, 'min_samples_split': 3.317076204933876e-10, 'min_samples_leaf': 3.0715503978971094e-06, 'min_weight_fraction_leaf': 0, 'max_features': 'log2', 'max_leaf_nodes': 30, 'min_impurity_decrease': 5.872440336362214e-05, 'oob_score': False, 'class_weight': 'balanced_subsample', 'ccp_alpha': 0.007816282151937592}\n"
     ]
    }
   ],
   "source": [
    "# # Hyperparameter tuning - Random Forest (using tune_sklearn)\n",
    "#pip install ray[tune] tune-sklearn\n",
    "#pip install scikit-optimize\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "#from skopt import BayesSearchCV\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['n_estimators'] = (1, 1000, 'uniform')\n",
    "hparams['criterion'] = ['gini', 'entropy']\n",
    "hparams['max_depth'] = (1,100, \"uniform\")\n",
    "hparams['min_samples_split'] = (1e-10, 9e-10, \"log-uniform\")\n",
    "hparams['min_samples_leaf'] = (1e-6, 0.5, \"log-uniform\")\n",
    "hparams['min_weight_fraction_leaf'] = (0, 0.5, \"log-uniform\")\n",
    "hparams['max_features'] = ['auto', 'sqrt', 'log2']\n",
    "hparams['max_leaf_nodes'] = (1,100, \"uniform\")\n",
    "hparams['min_impurity_decrease'] = (1e-6, 1e10, \"log-uniform\")\n",
    "#hparams['bootstrap'] = (True, False)\n",
    "hparams['oob_score'] = (True, False)\n",
    "#hparams['n_jobs'] = (-1, 1)\n",
    "hparams['class_weight'] = ('balanced', 'balanced_subsample')\n",
    "hparams['ccp_alpha'] = (1e-6, 1e10, \"log-uniform\")\n",
    "\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(RFC(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian',\n",
    "                           refit = True,\n",
    "                           verbose=0\n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fail_fast='raise' detected. Be careful when using this mode as resources (such as Ray processes, file descriptors, and temporary files) may not be cleaned up properly. To use a safer mode, use fail_fast=True.\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n",
      "Trial Runner checkpointing failed: cannot pickle 'dict_values' object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lsqr', 'shrinkage': None, 'tol': 0.028066745764403146}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - Random Forest (using tune_sklearn)\n",
    "#pip install ray[tune] tune-sklearn\n",
    "#pip install scikit-optimize\n",
    "\n",
    "from tune_sklearn import TuneSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "#from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "# define search space\n",
    "hparams = dict()\n",
    "hparams['solver'] = ['lsqr', 'eigen']\n",
    "hparams['shrinkage'] = (None,'auto')\n",
    "#hparams['n_components'] = (1, 2)\n",
    "hparams['tol'] = (1e-6, 1e10, \"log-uniform\")\n",
    "\n",
    "\n",
    "# Define evaluation\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define the search\n",
    "tune_search = TuneSearchCV(LDA(),\n",
    "                           param_distributions = hparams,\n",
    "                           use_gpu = False,\n",
    "                           cv = 10,\n",
    "                           n_jobs = 1,\n",
    "                           search_optimization = 'bayesian',\n",
    "                           refit = True,\n",
    "                           verbose=0\n",
    "                          )\n",
    "                      \n",
    "# Perform the search\n",
    "tune_search.fit(X, y.values.ravel())\n",
    "\n",
    "# Report the best result\n",
    "print(tune_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Iris-virginica'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-b23129d9fbc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mclf_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mclf_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Iris-virginica'"
     ]
    }
   ],
   "source": [
    "# Train SVM model using computed hyperparameters\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import sklearn.metrics as clf_metrics\n",
    "\n",
    "\n",
    "'''\n",
    "'C': 0.4632668689058262, \n",
    "'kernel': 'poly'\n",
    "'degree': 3\n",
    "'gamma': 0.008637473528650222, \n",
    "'coef0': 14.819346866218453\n",
    "'shrinking': True\n",
    "'tol': 0.01526285467501595\n",
    "'decision_function_shape': 'ovo'}\n",
    "'''\n",
    "\n",
    "model = SVC(C=0.4632668689058262, \n",
    "            kernel='poly',\n",
    "            degree=3,\n",
    "            gamma=0.008637473528650222,\n",
    "            coef0=14.819346866218453,\n",
    "            shrinking=True, \n",
    "            tol=0.01526285467501595, \n",
    "            decision_function_shape='ovo'\n",
    "           )\n",
    "\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "clf_metrics.confusion_matrix(y_test, y_pred)\n",
    "clf_metrics.roc_auc_score(y_true = y_test, y_score=y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-46a876838a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "print(hparams[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Modelagem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
